{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-7-qBkQ9nZPP2KUqQ9hrTRoCNB9YTqDd",
      "authorship_tag": "ABX9TyPFttpcqnMmWrqYE1ODtq8A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/tibame_0618/blob/main/tibame_0709_ptt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "403 Forbidden\n",
        "1. IP ban: 換ip\n",
        "2. 模仿的不像: 少了必要的Headers\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "faDvBjbn2q-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as req\n",
        "# 相對路徑\n",
        "# 1. a.txt: 現在目錄下的a.txt\n",
        "# 2. ./a.txt: 現在目錄下的a.txt\n",
        "# 3. ../a.txt: 前一層目錄下的a.txt\n",
        "\n",
        "def download_imgur_image(url, dirname=\".\"):\n",
        "    # url = \"https://i.imgur.com/OSwXeuz.jpeg\"\n",
        "    r = req.Request(url)\n",
        "    r.add_header(\"User-Agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/1\")\n",
        "    resp = req.urlopen(r)\n",
        "    content = resp.read()\n",
        "    # 純文字檔案(CSV, txt...): open(\"a.txt\", \"w/r\", encoding=\"utf-8\")\n",
        "    # 非純文字檔案(mp3, mp4, pdf, docs....): open(\"a.jpeg\", \"wb/rb\")\n",
        "    fp = dirname + \"/\" + url.split(\"/\")[-1]\n",
        "    with open(fp, \"wb\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "url = \"https://i.imgur.com/OSwXeuz.jpeg\"\n",
        "download_imgur_image(url)"
      ],
      "metadata": {
        "id": "ujg0qoj4v6qs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "pWTwDam31Q4G"
      },
      "outputs": [],
      "source": [
        "import urllib.request as req\n",
        "import json\n",
        "import bs4 as bs\n",
        "\n",
        "url = \"https://www.ptt.cc/bbs/Beauty/M.1751797464.A.265.html\"\n",
        "r = req.Request(url)\n",
        "r.add_header(\"User-Agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/1\")\n",
        "resp = req.urlopen(r)\n",
        "content = resp.read()\n",
        "html = bs.BeautifulSoup(content)\n",
        "# print(html)\n",
        "\n",
        "metas = html.find_all(\"span\", {\"class\":\"article-meta-value\"})\n",
        "author = metas[0]\n",
        "board = metas[1]\n",
        "title = metas[2]\n",
        "post_time = metas[3]\n",
        "push_datas = html.find_all(\"div\", {\"class\":\"push\"})\n",
        "\n",
        "\n",
        "author_text = author.text.strip()\n",
        "board_text = board.text.strip()\n",
        "title_text = title.text.strip()\n",
        "post_time_text = post_time.text.strip()\n",
        "\n",
        "pushes = []\n",
        "for p in push_datas:\n",
        "    push_meta = p.find_all(\"span\")\n",
        "    # extract\n",
        "    push_tag = push_meta[0]\n",
        "    push_uid = push_meta[1]\n",
        "    push_content = push_meta[2]\n",
        "    push_ipdatetime = push_meta[3]\n",
        "    trans = {\"推\":1, \"噓\":-1, \"→\":0}\n",
        "    # text\n",
        "    push_data = {\n",
        "        \"push_tag\":trans[push_tag.text.strip()],\n",
        "        \"push_uid\":push_uid.text.strip(),\n",
        "        \"push_content\":push_content.text.strip().replace(\": \", \"\"),\n",
        "        \"push_ipdatetime\":push_ipdatetime.text.strip()\n",
        "    }\n",
        "    pushes.append(push_data)\n",
        "\n",
        "# downlaod image\n",
        "allow = [\"png\", \"jpg\", \"jpeg\", \"gif\", \"webp\"]\n",
        "links = html.find_all(\"a\")\n",
        "for link in links:\n",
        "    href = link[\"href\"]\n",
        "    sub = href.split(\".\")[-1]\n",
        "    if sub.lower() in allow:\n",
        "        download_imgur_image(href)\n",
        "\n",
        "# 區塊.extract(): 在整份html裡消失\n",
        "main_content = html.find(\"div\", {\"id\":\"main-content\"})\n",
        "for e in main_content.find_all(\"div\", {\"class\":\"article-metaline\"}):\n",
        "    e.extract()\n",
        "for e in main_content.find_all(\"div\", {\"class\":\"article-metaline-right\"}):\n",
        "    e.extract()\n",
        "for e in main_content.find_all(\"div\", {\"class\":\"push\"}):\n",
        "    e.extract()\n",
        "content_text = main_content.text\n",
        "\n",
        "row = {\n",
        "    \"author\":author_text,\n",
        "    \"board\":board_text,\n",
        "    \"title\":title_text,\n",
        "    \"post_time\":post_time_text,\n",
        "    \"content\":content_text,\n",
        "    \"pushes\":pushes,\n",
        "}\n",
        "# print(row)\n",
        "\n",
        "\n",
        "fp = url.split(\"/\")[-1] + \".json\"\n",
        "f = open(fp, \"w\", encoding=\"utf-8\")\n",
        "json.dump(row, f, indent=4, ensure_ascii=False)\n",
        "f.close()"
      ]
    }
  ]
}